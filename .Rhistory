sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
sample <- rtweedie(N, mu = true_mu, phi = 1000, power = 1.9)
t.test(sample, mu = true_mu)
# Task 1 - Simulation of M samples
simTweedieTest <- t.test(rtweedie(N, mu = true_mu, phi = 100, power = 1.9),
mu = true_mu)$p.value
simTweedieTest
simulate(simTweedieTest)
simTweedieTest <- t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
simTweedieTest
simTweedieTest
simTweedieTest
simTweedieTest
# Task 1 - Simulation of M samples
simTweedieTest <- function(N){
t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
}
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)
simTweedieTest(N)       # Now it gives us the different p-values automatically
simTweedieTest(N)       # Now it gives us the different p-values automatically
MTweedieTests <- function(M, N, alpha) {
t.test(rtweedie(N, mu = 10000, phi = 100, power = 1.9),
mu = 10000)$p.value
}
MTweedieTests(10, N, .05)
MTweedieTests(10, N, .05)
MTweedieTests(10, N, .05)
snippet lib
install.packages("palmerpenguins")
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
library(tidyverse)
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
#| label: load-packages
#| include: false
library(tidyverse)
library(palmerpenguins)
#| label: plot-penguins
#| warning: false
#| echo: false
ggplot(penguins,
aes(x = flipper_length_mm, y = bill_length_mm)) +
geom_point(aes(color = species, shape = species)) +
scale_color_manual(values = c("darkorange","purple","cyan4")) +
labs(
title = "Flipper and bill length",
subtitle = "Dimensions for penguins at Palmer Station LTER",
x = "Flipper length (mm)", y = "Bill length (mm)",
color = "Penguin species", shape = "Penguin species"
) +
theme_minimal()
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
install.packages("DescTools")
library(DescTools)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
install.packages("anytime")
library(anytime)
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
# The URL we will use is stored below:
url <- "https://www.vegvesen.no/trafikkdata/api/"
# Let's figure out which sensor stations that are operable.
# The query below extracts all the stations, with a date for
# when the station was in operation as well as a long/latitude.
qry <-
'
{
trafficRegistrationPoints {
id
name
latestData {
volumeByDay
}
location {
coordinates {
latLon {
lat
lon
}
}
}
}
}
'
# Allright - let's try submitting the query:
stations <-GQL(qry)
length(stations)
length(stations[[1]])
stations[[1]][[1]]
stations[[1]][[1]] %>%
as_tibble()
stations[[1]][[1]]
length(stations)
length(stations[[1]])
stations[[1]] %>%
map(as_tibble) %>%
rbind()
# 1. A time consuming problem
library(tidyverse)
setwd("~/Desktop/NHH/Faglig/Master/BAN400/Parallel Computing")
setwd("~/Desktop/NHH/Faglig/Master/BAN400/Parallel Computing")
load("paralell_data.Rdata")
load("parallel_data.Rdata")
sales_price_mnok <- 1
car_cost_mnok <- .95
df %>%
head() %>%
knitr::kable()
View(df)
calcProfits <-
function(df,
sales_price_mnok,
car_cost_mnok,
lead_days) {
df %>%
mutate(
sales_price_BTC = sales_price_mnok / NOKBTC,
mNOK_val_sales =
lead(NOKBTC, lead_days, order_by = date)
* sales_price_BTC,
profit_mnok = mNOK_val_sales - car_cost_mnok
)
}
initial_equity <- 10
test_neg_equity <-
function(df, startdate, lead_days) {
tmpdf <-
df %>%
filter(date >= startdate) %>%
calcProfits(sales_price_mnok, car_cost_mnok, lead_days) %>%
filter(complete.cases(.))
if (nrow(tmpdf) > 0) {
tmpdf %>%
mutate(cumulative_profits_mnok = cumsum(profit_mnok)) %>%
summarise(negative_equity =
1 * (min(
cumulative_profits_mnok + initial_equity
) < 0)) %>%
pull %>%
return
} else{
return(NA_real_)
}
}
# Functionality storing how long time it takes to complete the calculation.
# Tictoc-library
library(tictoc)
install.packages("tictoc")
# Functionality storing how long time it takes to complete the calculation.
# Tictoc-library
library(tictoc)
# We can use tictoc to time a function..:
tic()
Sys.sleep(1)
toc()
# Tictoc storing to logs for comparing different experiments
printTicTocLog <-
function() {
tic.log() %>%
unlist %>%
tibble(logvals = .) %>%
separate(logvals,
sep = ":",
into = c("Function type", "log")) %>%
mutate(log = str_trim(log)) %>%
separate(log,
sep = "",
into = c("Seconds"),
extra = "drop")
}
tic.clearlog()
tic("Test")
Sys.sleep(1)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
printTicTocLog() %>%
knitr::kable()
# Result Data frame
df_res <-
expand.grid(date = df$date,
lead_days = c(1, 5, 10, 30, 60)) %>%
mutate(neg_eq = NA) %>%
as_tibble()
df_res
tic.clearlog()
tic("Regular loop")
for (i in 1:nrow(df_res)) {
df_res$neg_eq[i] <-
test_neg_equity(df,
startdate = df_res$date[i],
lead_days = df_res$lead_days[i])
}
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
printTicTocLog() %>%
knitr::kable()
# Sequence. Calculate cumulative sum
for (i in 1:nrow(df_res)) {
df_res$neg_eq[i] <-
test_neg_equity(df,
startdate = df_res$date[i],
lead_days = df_res$lead_days[i])
}
# ------------------9.5 Using multiple cores in R------------------------------
library(doParallel)
install.packages("doParallel")
# ------------------9.5 Using multiple cores in R------------------------------
library(doParallel)
# The function detectCores finds the number of cores
# available on the machine. We update the "Cores"-value
# to the minimum of the chosen cores and the available cores.
maxcores <- 8
Cores <- min(parallel::detectCores(), maxcores)
# Instantiate the cores:
cl <- makeCluster(Cores)
# Next we register the cluster..
registerDoParallel(cl)
res <-
foreach(
i = 1:nrow(df_res),
.combine = 'rbind',
.packages = c('magrittr', 'dplyr')
) %dopar%
tibble(
date = df_res$date[i],
lead_days = df_res$lead_days[i],
neg_eq =
test_neg_equity(
df,
startdate = df_res$date[i],
lead_days = df_res$lead_days[i]
)
)
# Now that we're done, we close off the clusters
stopCluster(cl)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
#------------------------------9.6 Using Purr----------------------------------
library(purrr)
df_res$neg_eq <-
df %>%
map2_dbl(as.list(df_res$date),
as.list(df_res$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
toc()
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
library(furrr)
plan(multisession, workers = Cores)
tic(paste0("furrr, ", Cores, " cores"))
df_res$neg_eq <-
df %>%
future_map2_dbl(as.list(df_res$date),
as.list(df_res$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
for (Cores in 1:maxcores) {
plan(multisession, workers = Cores)
tic(paste0("furrr, ", Cores, " cores"))
df_res$neg_eq <-
df %>%
future_map2_dbl(as.list(df_res$date),
as.list(df_res$lead_days),
test_neg_equity,
df = .)
toc(log = TRUE)
}
# Illustration
printTicTocLog() %>%
tail(maxcores) %>%
separate(
`Function type`,
sep = " ",
into = c("Function type", "nCores"),
extra = "drop"
) %>%
mutate(
Seconds = as.numeric(Seconds),
nCores = as.numeric(nCores),
lowered_compute_time = Seconds / lag(Seconds, order_by = nCores) - 1,
theoretical_max = lag(nCores) / nCores - 1
) %>%
ggplot(aes(x = nCores)) +
geom_line(aes(y = lowered_compute_time, col = "Realized performance gain")) +
geom_line(aes(y = theoretical_max, col = "Theoretical performance gain")) +
theme_classic() +
xlab("Number of cores") +
ylab("Lowered compute time by additional core") +
theme(legend.title = element_blank(),
legend.position = 'bottom')
setwd("/Users/tinnguyen/Desktop/parallel-computing-tinnguy3n")
rm(list = ls())
# Assignment 1:
library(tweedie)
library(ggplot2)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
simTweedieTest()
# Assignment 2:
MTweedieTests <-
function(N,M,sig){
sum(replicate(M,simTweedieTest(N)) < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
df
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N=df$N[i],
M=df$M[i],
sig=.05)
}
library(magrittr)
library(tidyverse)
simDat <-
function(N, type, mu) {
if (type == "tweedie") {
return(rtweedie(
N,
mu = mu,
phi = 100,
power = 1.9
))
}
if (type == "normal") {
return(rnorm(N, mean = mu))
}
else{
stop("invalid distribution")
}
}
# Next, the test. Note, we use mu two places:
# both for the data simulation and as the null.
simTest <-
function(N, type, mu) {
t.test(simDat(N = N,
type = type,
mu = mu),
mu = mu)$p.value
}
# Running many tests is almost the same as before.
# Here the mean is hard coded in, as we're not
# going to change it.
MTests <-
function(N, M, type, sig) {
sum(replicate(M,
simTest(
N = N,
type =
type,
mu =
10000
)) < sig) / M
}
# We can now repeat the same analysis as before,
# but for both the tweedie and the normal:
df <-
expand.grid(
N = c(10, 100, 1000, 5000),
M = 1000,
type = c("tweedie", "normal"),
share_reject = NA
) %>%
as_tibble()
for (i in 1:nrow(df)) {
print(i)
df$share_reject[i] <-
MTests(df$N[i],
df$M[i],
df$type[i],
.05)
}
# As you see, with normally distributed data, N can
# be very small and the t-test is fine. With a tweedie,
# "large enough" can be many thousands. If we try
# different distributions or parameterizations, we might
# also get different results.
df %>%
ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
geom_line() +
geom_hline(yintercept = .05) +
theme_bw()
# Instantiate the cores:
cores <- detectCores()
cl <- makeCluster(cores - 1)
# Next we register the cluster.
registerDoParallel(cl)
# Rewritten line for Parallel Computing
results <-
foreach(i = 1:nrow(df),
# Combines results from each ireation.
.combine = c,
# Ensures tweedie package is available for each parallel, because of MTweedieTests
.packages = "tweedie") %dopar% {
MTweedieTests(
N=df$N[i],
M=df$M[i],
sig=.05)
}
results
# Storing results
df$share_reject <- unlist(results)
df
# Stop Cluster
stopCluster(cl)
